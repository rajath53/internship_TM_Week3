{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4ddWxzuRCwdV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Titanic-Dataset.csv')"
      ],
      "metadata": {
        "id": "5b4wKSUHGJWD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "LXYJw3dUUp7g",
        "outputId": "0aeb8f94-6492-4d0f-89ef-13775641e90e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
              "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
              "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
              "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
              "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
              "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
              "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
              "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
              "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
              "\n",
              "            Parch        Fare  \n",
              "count  891.000000  891.000000  \n",
              "mean     0.381594   32.204208  \n",
              "std      0.806057   49.693429  \n",
              "min      0.000000    0.000000  \n",
              "25%      0.000000    7.910400  \n",
              "50%      0.000000   14.454200  \n",
              "75%      0.000000   31.000000  \n",
              "max      6.000000  512.329200  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aabe605c-3a3b-46e2-8e5c-4ac5803c51c4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>714.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.383838</td>\n",
              "      <td>2.308642</td>\n",
              "      <td>29.699118</td>\n",
              "      <td>0.523008</td>\n",
              "      <td>0.381594</td>\n",
              "      <td>32.204208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>257.353842</td>\n",
              "      <td>0.486592</td>\n",
              "      <td>0.836071</td>\n",
              "      <td>14.526497</td>\n",
              "      <td>1.102743</td>\n",
              "      <td>0.806057</td>\n",
              "      <td>49.693429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>223.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>20.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.910400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.454200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>668.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aabe605c-3a3b-46e2-8e5c-4ac5803c51c4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aabe605c-3a3b-46e2-8e5c-4ac5803c51c4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aabe605c-3a3b-46e2-8e5c-4ac5803c51c4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tb4qthPUuXx",
        "outputId": "352f4e6a-2e06-429f-d864-990ef7a07e9c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Titanic dataset\n",
        "train_data = pd.read_csv('/content/Titanic-Dataset.csv')\n",
        "\n",
        "# Preprocess the data\n",
        "train_data['Sex'] = train_data['Sex'].replace({'male': 0, 'female': 1})\n",
        "train_data['Embarked'] = train_data['Embarked'].fillna('S')\n",
        "train_data['Embarked'] = train_data['Embarked'].replace({'S': 0, 'C': 1, 'Q': 2})\n",
        "train_data['Age'] = train_data['Age'].fillna(train_data['Age'].mean())\n",
        "\n",
        "# Split the data into features and target\n",
        "X_train = train_data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
        "y_train = train_data['Survived']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_size = int(0.8 * len(X_train))\n",
        "X_train, X_test = X_train[:train_size], X_train[train_size:]\n",
        "y_train, y_test = y_train[:train_size], y_train[train_size:]\n"
      ],
      "metadata": {
        "id": "vxZe33dzG5vO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "nEgFnWLjU4jr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.read_csv(\"Titanic-Dataset.csv\")\n",
        "y = X.pop('Survived')"
      ],
      "metadata": {
        "id": "65hZRNc8U_s5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "SEED = 42\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state=SEED)"
      ],
      "metadata": {
        "id": "qy6Qlo72U_fr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qbhWG3guV1mP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jKqmcaEqV3Th"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    '''\n",
        "    Helper class which implements a single tree node.\n",
        "    '''\n",
        "    def __init__(self, feature=None, threshold=None, data_left=None, data_right=None, gain=None, value=None):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.data_left = data_left\n",
        "        self.data_right = data_right\n",
        "        self.gain = gain\n",
        "        self.value = value\n"
      ],
      "metadata": {
        "id": "cZg8jljULBGq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTree:\n",
        "    '''\n",
        "    Class which implements a decision tree classifier algorithm.\n",
        "    '''\n",
        "    def __init__(self, min_samples_split=2, max_depth=5):\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "        self.root = None\n",
        "        \n",
        "    @staticmethod\n",
        "    def _entropy(s):\n",
        "        '''\n",
        "        Helper function, calculates entropy from an array of integer values.\n",
        "        \n",
        "        :param s: list\n",
        "        :return: float, entropy value\n",
        "        '''\n",
        "        # Convert to integers to avoid runtime errors\n",
        "        counts = np.bincount(np.array(s, dtype=np.int64))\n",
        "        # Probabilities of each class label\n",
        "        percentages = counts / len(s)\n",
        "\n",
        "        # Caclulate entropy\n",
        "        entropy = 0\n",
        "        for pct in percentages:\n",
        "            if pct > 0:\n",
        "                entropy += pct * np.log2(pct)\n",
        "        return -entropy\n",
        "    \n",
        "    def _information_gain(self, parent, left_child, right_child):\n",
        "        '''\n",
        "        Helper function, calculates information gain from a parent and two child nodes.\n",
        "        \n",
        "        :param parent: list, the parent node\n",
        "        :param left_child: list, left child of a parent\n",
        "        :param right_child: list, right child of a parent\n",
        "        :return: float, information gain\n",
        "        '''\n",
        "        num_left = len(left_child) / len(parent)\n",
        "        num_right = len(right_child) / len(parent)\n",
        "        \n",
        "        # One-liner which implements the previously discussed formula\n",
        "        return self._entropy(parent) - (num_left * self._entropy(left_child) + num_right * self._entropy(right_child))\n",
        "    \n",
        "    def _best_split(self, X, y):\n",
        "        '''\n",
        "        Helper function, calculates the best split for given features and target\n",
        "        \n",
        "        :param X: np.array, features\n",
        "        :param y: np.array or list, target\n",
        "        :return: dict\n",
        "        '''\n",
        "        best_split = {}\n",
        "        best_info_gain = -1\n",
        "        n_rows, n_cols = X.shape\n",
        "        \n",
        "        # For every dataset feature\n",
        "        for f_idx in range(n_cols):\n",
        "            X_curr = X[:, f_idx]\n",
        "            # For every unique value of that feature\n",
        "            for threshold in np.unique(X_curr):\n",
        "                # Construct a dataset and split it to the left and right parts\n",
        "                # Left part includes records lower or equal to the threshold\n",
        "                # Right part includes records higher than the threshold\n",
        "                df = np.concatenate((X, y.reshape(1, -1).T), axis=1)\n",
        "                df_left = np.array([row for row in df if row[f_idx] <= threshold])\n",
        "                df_right = np.array([row for row in df if row[f_idx] > threshold])\n",
        "\n",
        "                # Do the calculation only if there's data in both subsets\n",
        "                if len(df_left) > 0 and len(df_right) > 0:\n",
        "                    # Obtain the value of the target variable for subsets\n",
        "                    y = df[:, -1]\n",
        "                    y_left = df_left[:, -1]\n",
        "                    y_right = df_right[:, -1]\n",
        "\n",
        "                    # Caclulate the information gain and save the split parameters\n",
        "                    # if the current split if better then the previous best\n",
        "                    gain = self._information_gain(y, y_left, y_right)\n",
        "                    if gain > best_info_gain:\n",
        "                        best_split = {\n",
        "                            'feature_index': f_idx,\n",
        "                            'threshold': threshold,\n",
        "                            'df_left': df_left,\n",
        "                            'df_right': df_right,\n",
        "                            'gain': gain\n",
        "                        }\n",
        "                        best_info_gain = gain\n",
        "        return best_split\n",
        "    \n",
        "    def _build(self, X, y, depth=0):\n",
        "        '''\n",
        "        Helper recursive function, used to build a decision tree from the input data.\n",
        "        \n",
        "        :param X: np.array, features\n",
        "        :param y: np.array or list, target\n",
        "        :param depth: current depth of a tree, used as a stopping criteria\n",
        "        :return: Node\n",
        "        '''\n",
        "        n_rows, n_cols = X.shape\n",
        "        \n",
        "        # Check to see if a node should be leaf node\n",
        "        if n_rows >= self.min_samples_split and depth <= self.max_depth:\n",
        "            # Get the best split\n",
        "            best = self._best_split(X, y)\n",
        "            # If the split isn't pure\n",
        "            if best['gain'] > 0:\n",
        "                # Build a tree on the left\n",
        "                left = self._build(\n",
        "                    X=best['df_left'][:, :-1], \n",
        "                    y=best['df_left'][:, -1], \n",
        "                    depth=depth + 1\n",
        "                )\n",
        "                right = self._build(\n",
        "                    X=best['df_right'][:, :-1], \n",
        "                    y=best['df_right'][:, -1], \n",
        "                    depth=depth + 1\n",
        "                )\n",
        "                return Node(\n",
        "                    feature=best['feature_index'], \n",
        "                    threshold=best['threshold'], \n",
        "                    data_left=left, \n",
        "                    data_right=right, \n",
        "                    gain=best['gain']\n",
        "                )\n",
        "        # Leaf node - value is the most common target value \n",
        "        return Node(\n",
        "            value=Counter(y).most_common(1)[0][0]\n",
        "        )\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        '''\n",
        "        Function used to train a decision tree classifier model.\n",
        "        \n",
        "        :param X: np.array, features\n",
        "        :param y: np.array or list, target\n",
        "        :return: None\n",
        "        '''\n",
        "        # Call a recursive function to build the tree\n",
        "        self.root = self._build(X, y)\n",
        "        \n",
        "    def _predict(self, x, tree):\n",
        "        '''\n",
        "        Helper recursive function, used to predict a single instance (tree traversal).\n",
        "        \n",
        "        :param x: single observation\n",
        "        :param tree: built tree\n",
        "        :return: float, predicted class\n",
        "        '''\n",
        "        # Leaf node\n",
        "        if tree.value != None:\n",
        "            return tree.value\n",
        "        feature_value = x[tree.feature]\n",
        "        \n",
        "        # Go to the left\n",
        "        if feature_value <= tree.threshold:\n",
        "            return self._predict(x=x, tree=tree.data_left)\n",
        "        \n",
        "        # Go to the right\n",
        "        if feature_value > tree.threshold:\n",
        "            return self._predict(x=x, tree=tree.data_right)\n",
        "        \n",
        "    def predict(self, X):\n",
        "        '''\n",
        "        Function used to classify new instances.\n",
        "        \n",
        "        :param X: np.array, features\n",
        "        :return: np.array, predicted classes\n",
        "        '''\n",
        "        # Call the _predict() function for every observation\n",
        "        return [self._predict(x, self.root) for x in X]"
      ],
      "metadata": {
        "id": "zgoAz_gfLBKB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomForest:\n",
        "    '''\n",
        "    A class that implements Random Forest algorithm from scratch.\n",
        "    '''\n",
        "    def __init__(self, num_trees=25, min_samples_split=2, max_depth=5):\n",
        "        self.num_trees = num_trees\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "        # Will store individually trained decision trees\n",
        "        self.decision_trees = []\n",
        "        \n",
        "    @staticmethod\n",
        "    def _sample(X, y):\n",
        "        '''\n",
        "        Helper function used for boostrap sampling.\n",
        "        \n",
        "        :param X: np.array, features\n",
        "        :param y: np.array, target\n",
        "        :return: tuple (sample of features, sample of target)\n",
        "        '''\n",
        "        n_rows, n_cols = X.shape\n",
        "        # Sample with replacement\n",
        "        samples = np.random.choice(a=n_rows, size=n_rows, replace=True)\n",
        "        return X[samples], y[samples]\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        '''\n",
        "        Trains a Random Forest classifier.\n",
        "        \n",
        "        :param X: np.array, features\n",
        "        :param y: np.array, target\n",
        "        :return: None\n",
        "        '''\n",
        "        # Reset\n",
        "        if len(self.decision_trees) > 0:\n",
        "            self.decision_trees = []\n",
        "            \n",
        "        # Build each tree of the forest\n",
        "        num_built = 0\n",
        "        while num_built < self.num_trees:\n",
        "            try:\n",
        "                clf = DecisionTree(\n",
        "                    min_samples_split=self.min_samples_split,\n",
        "                    max_depth=self.max_depth\n",
        "                )\n",
        "                # Obtain data sample\n",
        "                _X, _y = self._sample(X, y)\n",
        "                # Train\n",
        "                clf.fit(_X, _y)\n",
        "                # Save the classifier\n",
        "                self.decision_trees.append(clf)\n",
        "                num_built += 1\n",
        "            except Exception as e:\n",
        "                continue\n",
        "    \n",
        "    def predict(self, X):\n",
        "        '''\n",
        "        Predicts class labels for new data instances.\n",
        "        \n",
        "        :param X: np.array, new instances to predict\n",
        "        :return: \n",
        "        '''\n",
        "        # Make predictions with every tree in the forest\n",
        "        y = []\n",
        "        for tree in self.decision_trees:\n",
        "            y.append(tree.predict(X))\n",
        "        \n",
        "        # Reshape so we can find the most common value\n",
        "        y = np.swapaxes(a=y, axis1=0, axis2=1)\n",
        "        \n",
        "        # Use majority voting for the final prediction\n",
        "        predictions = []\n",
        "        for preds in y: \n",
        "            counter = Counter(x)\n",
        "            predictions.append(counter.most_common(1)[0][0])\n",
        "        return predictions"
      ],
      "metadata": {
        "id": "mJwy8FB-J-q3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ys2kkEYpI2a5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForest()\n",
        "model.fit(X_train, y_train)\n",
        "preds = model.predict(X_test)"
      ],
      "metadata": {
        "id": "8BhTMKS_JJSj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}